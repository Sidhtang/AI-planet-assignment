{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPF/PvtpeJlAsfLCRovHbhA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sidhtang/AI-planet-assignment/blob/main/crypto_price_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EF2PRcWlRzBG",
        "outputId": "a062a454-cd11-4041-c04f-61c9e9349197"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.43)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.4)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2024.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.4)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.6)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ta"
      ],
      "metadata": {
        "id": "yvqJXaxvTVfE",
        "outputId": "5c9fdff4-5652-48fc-f96f-78f544b9f3c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ta\n",
            "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ta) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.16.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29412 sha256=46ae143a1fbd82c8e8e63d797c7c43b97cc63b1a09d11f2fd441e2de466c9475\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/67/4f/8a9f252836e053e532c6587a3230bc72a4deb16b03a829610b\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from ta.trend import SMAIndicator, EMAIndicator\n",
        "from ta.momentum import RSIIndicator\n",
        "from ta.volatility import BollingerBands\n",
        "\n",
        "# 1. Enhanced Data Collection\n",
        "def get_crypto_data(symbol, start_date, end_date):\n",
        "    data = yf.download(symbol, start=start_date, end=end_date)\n",
        "    return data\n",
        "\n",
        "# 2. Improved Feature Engineering\n",
        "def engineer_features(data, sequence_length):\n",
        "    df = data.copy()\n",
        "\n",
        "    # Add technical indicators\n",
        "    df['SMA'] = SMAIndicator(close=df['Close'], window=14).sma_indicator()\n",
        "    df['EMA'] = EMAIndicator(close=df['Close'], window=14).ema_indicator()\n",
        "    df['RSI'] = RSIIndicator(close=df['Close'], window=14).rsi()\n",
        "    bb = BollingerBands(close=df['Close'], window=20, window_dev=2)\n",
        "    df['BB_upper'] = bb.bollinger_hband()\n",
        "    df['BB_lower'] = bb.bollinger_lband()\n",
        "\n",
        "    # Calculate returns\n",
        "    df['Returns'] = df['Close'].pct_change()\n",
        "\n",
        "    # Use all features\n",
        "    features = ['Close', 'Volume', 'SMA', 'EMA', 'RSI', 'BB_upper', 'BB_lower', 'Returns']\n",
        "    df = df[features].dropna()\n",
        "\n",
        "    # Normalize the data\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    scaled_data = scaler.fit_transform(df)\n",
        "\n",
        "    # Create sequences\n",
        "    X, y = [], []\n",
        "    for i in range(len(scaled_data) - sequence_length):\n",
        "        X.append(scaled_data[i:(i + sequence_length), :])\n",
        "        y.append(1 if scaled_data[i + sequence_length, 0] > scaled_data[i + sequence_length - 1, 0] else 0)\n",
        "\n",
        "    return np.array(X), np.array(y), scaler\n",
        "\n",
        "# 3. Improved Model Creation\n",
        "def create_model(input_shape):\n",
        "    model = Sequential([\n",
        "        LSTM(100, return_sequences=True, input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        LSTM(100, return_sequences=True),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        LSTM(100, return_sequences=False),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(50, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# 4. Improved Model Training\n",
        "def train_model(X, y):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model = create_model((X.shape[1], X.shape[2]))\n",
        "\n",
        "    # Callbacks for better training\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[early_stopping, reduce_lr],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    return model, X_test, y_test, history\n",
        "\n",
        "# 5. Model Evaluation (unchanged)\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage\n",
        "    symbol = \"BTC-USD\"\n",
        "    start_date = \"2018-01-01\"  # Extended date range for more data\n",
        "    end_date = \"2023-12-31\"\n",
        "    sequence_length = 60  # Number of previous days to use for prediction\n",
        "\n",
        "    # Get data\n",
        "    data = get_crypto_data(symbol, start_date, end_date)\n",
        "\n",
        "    # Engineer features\n",
        "    X, y, scaler = engineer_features(data, sequence_length)\n",
        "\n",
        "    # Train model\n",
        "    model, X_test, y_test, history = train_model(X, y)\n",
        "\n",
        "    # Evaluate model\n",
        "    accuracy, report = evaluate_model(model, X_test, y_test)\n",
        "\n",
        "    print(f\"Model Accuracy: {accuracy}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n",
        "\n",
        "    # Make a prediction for the next day\n",
        "    last_sequence = X[-1:]\n",
        "    prediction = model.predict(last_sequence)\n",
        "\n",
        "    print(f\"Prediction for next day: {'Up' if prediction[0,0] > 0.5 else 'Down'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d32PPCI3R2Hi",
        "outputId": "04103939-25fb-4058-81c1-89fb677b0589"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5360 - loss: 0.8413 - val_accuracy: 0.4024 - val_loss: 0.6997 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.4863 - loss: 0.8255 - val_accuracy: 0.4556 - val_loss: 0.7001 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4850 - loss: 0.7956 - val_accuracy: 0.4379 - val_loss: 0.6941 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5132 - loss: 0.7677 - val_accuracy: 0.5030 - val_loss: 0.6989 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4952 - loss: 0.7539 - val_accuracy: 0.5266 - val_loss: 0.7054 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.5146 - loss: 0.7480 - val_accuracy: 0.5266 - val_loss: 0.7147 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4934 - loss: 0.7428 - val_accuracy: 0.4852 - val_loss: 0.6968 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4904 - loss: 0.7310 - val_accuracy: 0.5444 - val_loss: 0.6906 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.4923 - loss: 0.7368 - val_accuracy: 0.5148 - val_loss: 0.6916 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5117 - loss: 0.7154 - val_accuracy: 0.5148 - val_loss: 0.6910 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4738 - loss: 0.7344 - val_accuracy: 0.4320 - val_loss: 0.7038 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4788 - loss: 0.7265 - val_accuracy: 0.5325 - val_loss: 0.6883 - learning_rate: 0.0010\n",
            "Epoch 13/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4873 - loss: 0.7149 - val_accuracy: 0.5562 - val_loss: 0.6898 - learning_rate: 0.0010\n",
            "Epoch 14/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5024 - loss: 0.7121 - val_accuracy: 0.5148 - val_loss: 0.6897 - learning_rate: 0.0010\n",
            "Epoch 15/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5169 - loss: 0.7173 - val_accuracy: 0.5740 - val_loss: 0.6844 - learning_rate: 0.0010\n",
            "Epoch 16/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5006 - loss: 0.7132 - val_accuracy: 0.4911 - val_loss: 0.6919 - learning_rate: 0.0010\n",
            "Epoch 17/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4899 - loss: 0.7130 - val_accuracy: 0.5266 - val_loss: 0.6844 - learning_rate: 0.0010\n",
            "Epoch 18/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5112 - loss: 0.7049 - val_accuracy: 0.5444 - val_loss: 0.6905 - learning_rate: 0.0010\n",
            "Epoch 19/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4822 - loss: 0.7034 - val_accuracy: 0.4970 - val_loss: 0.6941 - learning_rate: 0.0010\n",
            "Epoch 20/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4924 - loss: 0.7088 - val_accuracy: 0.5680 - val_loss: 0.6814 - learning_rate: 0.0010\n",
            "Epoch 21/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.5043 - loss: 0.7062 - val_accuracy: 0.5325 - val_loss: 0.6863 - learning_rate: 0.0010\n",
            "Epoch 22/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.5075 - loss: 0.7027 - val_accuracy: 0.5385 - val_loss: 0.6859 - learning_rate: 0.0010\n",
            "Epoch 23/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5030 - loss: 0.6996 - val_accuracy: 0.5503 - val_loss: 0.6856 - learning_rate: 0.0010\n",
            "Epoch 24/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5007 - loss: 0.6944 - val_accuracy: 0.5385 - val_loss: 0.6865 - learning_rate: 0.0010\n",
            "Epoch 25/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5041 - loss: 0.6988 - val_accuracy: 0.5562 - val_loss: 0.6852 - learning_rate: 0.0010\n",
            "Epoch 26/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5111 - loss: 0.6979 - val_accuracy: 0.5266 - val_loss: 0.6850 - learning_rate: 2.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5434 - loss: 0.6855 - val_accuracy: 0.5858 - val_loss: 0.6838 - learning_rate: 2.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5328 - loss: 0.6888 - val_accuracy: 0.5740 - val_loss: 0.6851 - learning_rate: 2.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5310 - loss: 0.6946 - val_accuracy: 0.5799 - val_loss: 0.6864 - learning_rate: 2.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5486 - loss: 0.6894 - val_accuracy: 0.5503 - val_loss: 0.6868 - learning_rate: 2.0000e-04\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
            "Model Accuracy: 0.47754137115839246\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.23      0.31       220\n",
            "           1       0.47      0.75      0.58       203\n",
            "\n",
            "    accuracy                           0.48       423\n",
            "   macro avg       0.48      0.49      0.45       423\n",
            "weighted avg       0.48      0.48      0.44       423\n",
            "\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Prediction for next day: Down\n"
          ]
        }
      ]
    }
  ]
}